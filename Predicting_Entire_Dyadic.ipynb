{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import helpers\n",
    "import sarcastic\n",
    "from engagement import engagement_preprocessing\n",
    "from satisfaction import satisfaction_preprocessing\n",
    "from helpers import round_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train sarcasm classification model \n",
    "tokenizer, model = sarcastic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_name = \"depressed\"\n",
    "\n",
    "in_path = \"data/RED/clean/\" + subreddit_name + \"_clean.csv\"\n",
    "out_path = \"data/RED/clean/labeled/\" + subreddit_name + \"_clean_labeled.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(in_path)\n",
    "df = df.rename(columns={'conversation id': 'conversation_id', 'post title': 'post_title', 'dialog turn': 'dialog_turn', 'emotion prediction': 'emotion_prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group conversations by conversation_id and subreddit\n",
    "grouped = df.groupby(['conversation_id', 'subreddit']).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST HYPERPARAMETERS \n",
    "\n",
    "eng_threshold = 2.75\n",
    "num_turns_weight = 0.75\n",
    "interleaved_weight = 0.75\n",
    "token_length_weight = 0.025\n",
    "diff_weight = -0.25\n",
    "\n",
    "sat_threshold = 0.6\n",
    "slope_weight = 0.5\n",
    "sentiment_change_weight = 0.5\n",
    "grateful_bonus_weight = 3.25\n",
    "profanity_penalty_weight = 0.5\n",
    "sarcasm_penalty_weight = 0.5\n",
    "disagreement_penalty_weight = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT ENGAGEMENT AND SATISFACTION USING BEST HYPERPARAMETERS ON DATASET \n",
    "\n",
    "start = time.time()\n",
    "cols = df.columns.tolist()\n",
    "df_preds = pd.DataFrame(columns=cols)\n",
    "\n",
    "for conv_id, subreddit in grouped:\n",
    "    conversation, speaker, listener = helpers.extract_responses(conv_id, subreddit, df)\n",
    "    \n",
    "    # Predict engagement\n",
    "    num_turns, interleaved, token_length_score, num_turn_diff, conversation = engagement_preprocessing(speaker, listener, conversation)\n",
    "    engagement_score = num_turns_weight*num_turns + interleaved_weight*interleaved + token_length_weight*token_length_score + diff_weight*num_turn_diff\n",
    "    engagement = 1 if engagement_score >= eng_threshold else 0\n",
    "    conversation['predicted_engagement'] = engagement\n",
    "    \n",
    "    # Predict satisfaction\n",
    "    slope, sentiment_change, grateful_bonus, profanity_penalty, sarcasm_penalty, disagreement_penalty = satisfaction_preprocessing(conversation, speaker, tokenizer, model)\n",
    "    satisfaction_score = slope_weight*slope + sentiment_change_weight*sentiment_change + grateful_bonus_weight*grateful_bonus + profanity_penalty_weight*profanity_penalty + sarcasm_penalty_weight*sarcasm_penalty + disagreement_penalty_weight*disagreement_penalty\n",
    "    satisfaction = 1 if satisfaction_score >= sat_threshold else 0\n",
    "    conversation['predicted_satisfaction'] = satisfaction\n",
    "    \n",
    "    df_preds = df_preds.append(conversation)\n",
    "\n",
    "df_preds = df_preds[['conversation_id', 'subreddit', 'post_title', 'author', 'dialog_turn', 'text', 'predicted_satisfaction', 'predicted_engagement', 'compound', 'sentiment', 'emotion_prediction', 'token_length', 'sentences', 'sentence_compounds', 'strongest_compound']]\n",
    "\n",
    "df_preds.to_csv(out_path, index=False)\n",
    "\n",
    "end = time.time()\n",
    "minutes = (end - start) / 60\n",
    "print('Time it takes to predict for dataset (in minutes):', minutes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
